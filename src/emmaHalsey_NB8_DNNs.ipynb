{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1600351e-2b0f-4db1-8d04-59217598f4b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Notebook 8: Deep Neural Networks (DNNs)\n",
    "=======================================\n",
    "\n",
    "## Goals for learning\n",
    "In this assignment, we will:\n",
    "1) Introduce the **[PyTorch](https://pytorch.org/)** and TorchVision libraries for working with deep neural networks.\n",
    "2) Practice **image classification** with deep neural netowrks.\n",
    "\n",
    "## Instructions\n",
    "* Read through the notebook.\n",
    "* Answer any plain text questions (replace cell content, \"YOUR RESPONSE HERE\", with your response).\n",
    "* Insert your code within the code blocks marked with the comments \"# START your code here\" and \"# STOP your code here\".\n",
    "* Do not use loops, iteration, or recursion in any of the code cells (except where explicitly allowed).\n",
    "* When transforming collections of items in the same manner, do not simply copy/paste with an index into each item. Instead, you should be using array operations.\n",
    "* Do not use any \"Generative AI\" tools or assistants in the creation of your solutions.\n",
    "* Do not import or use any libraries other than those already imported outside the \"# START your code here\" and \"# STOP your code here\" blocks.\n",
    "    * In some blocks, you are not allowed to use certain numpy and pandas methods. Please pay attention to the \"TO DO\" instructions.\n",
    "* Run all cells to make sure your code works and you see reasonable results.\n",
    "    * All code cells should have output indicating the results of the last run when the notebook is submitted.\n",
    "    * If there are errors, or if a code cell does not have output as submittted, points will be deducted.\n",
    "\n",
    "## Submission details\n",
    "* Due: Monday 11/10, 11:59 PM\n",
    "* [Submission instructions](https://www.cs.oswego.edu/~agraci2/csc461/submission_instructions.html)\n",
    "\n",
    "## Background\n",
    "Previously in NB7, we implemented a neuron from scratch to better gain intuitions about the underlying mechanics of how basic neural networks operate. In this project, we will be working with libraries that enable us to operate at a higher level of abstraction but try to keep in mind what is going on under the hood!\n",
    "\n",
    "## Notebook Premise\n",
    "You are working for a software company that is developing an app that digitizes handwritten ledgers. You are tasked with implementing an **image classifier** to recognize handwritten digits, using a **neural network**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4f36c-8f4c-44a5-aff6-1cc5209da272",
   "metadata": {},
   "source": [
    "## About the data set\n",
    "The [MNIST database](https://en.wikipedia.org/wiki/MNIST_database) is a large set of handwritten digits (labeled 0-9), formatted as 28x28 pixel grayscale images. \n",
    "\n",
    "Although the database is available for download in binary format from [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/), we will be using the TorchVision API to retrieve and load the data for us in this notebook.\n",
    "\n",
    "## Python library dependencies\n",
    "* [Pytorch](https://pytorch.org/) - \"PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.\" \n",
    "* [TorchVision](https://pytorch.org/vision/stable/index.html) - \"The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a969911-7f66-4ebd-8a96-c0998b39fd9c",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "### Loading data with TorchVision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f275d38-f0eb-49ea-906f-91d9d40acf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set the seed for random calls to enhance reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Data will be cached down one directory from where you are currently working. The data should not be included in your assignment submission.\n",
    "DOWNLOAD_DATA=True\n",
    "MNIST_DOWNLOAD_ROOT='./mnist_torch/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ad5938-3916-434b-804a-bb310c9d41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to load the MNIST dataset. Returns a training data set and an evaluation data set.\n",
    "def LoadDataMNIST(normalize=True, base_path=MNIST_DOWNLOAD_ROOT, download=True):\n",
    "\n",
    "    # Modify the output path for normalized data\n",
    "    if normalize:\n",
    "        base_path = base_path + \"norm\"\n",
    "    else:\n",
    "        base_path = base_path + \"nonorm\"\n",
    "\n",
    "    # Define transformations to apply to the data\n",
    "    transformation_list = []\n",
    "    transformation_list.append(transforms.ToTensor()) # Convert to \"tensor\"\n",
    "    if normalize:\n",
    "        transformation_list.append(transforms.Normalize((0.5,), (0.5,))) # Normalize the data\n",
    "    transform = transforms.Compose(transformation_list)\n",
    "\n",
    "    # Load (or download) our training and test datasets\n",
    "    train_data = torchvision.datasets.MNIST(\n",
    "        root=base_path, \n",
    "        train=True,\n",
    "        download=download, \n",
    "        transform=transform)\n",
    "    \n",
    "    # Load (or download) our training and test datasets\n",
    "    eval_data = torchvision.datasets.MNIST(\n",
    "        root=base_path, \n",
    "        train=False,\n",
    "        download=download, \n",
    "        transform=transform)\n",
    "    \n",
    "    return train_data, eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250e3854-429a-4cd7-9e4c-71448b252e06",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download the training and evaluation dataset\n",
    "train_data, eval_data = LoadDataMNIST(normalize=True, base_path=MNIST_DOWNLOAD_ROOT, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2333fb-9bc9-4c6c-a835-7729f3e6c63d",
   "metadata": {},
   "source": [
    "Now that **TorchVision** handled **downloading** and **transforming** our data for us, we can use **PyTorch** to **batch** and **shuffle** our data for us using the [DataLoader](https://docs.pytorch.org/docs/stable/data.html) interface.\n",
    "\n",
    "When we go to train our model with the Gradient Descent algorithm, the batch size will determine which type of gradient descent we are performing:\n",
    "* Batch size of 1: \"Stochastic\" gradient descent\n",
    "* Batchsize > 1 but < the size of the dataset: \"Mini-batch\" gradient descent\n",
    "* Batch size equals the size of the dataset: \"Batch\" gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a52ce96a-476c-4a9a-8aa1-3d3c872ad13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # Number of image samples to look at per training iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16372707-3525-48f0-9509-9067aff4ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to greate a data loader for the training set and the evaluation set\n",
    "def GetDataLoaders(train_data, eval_data, batch_size_train, batch_size_eval):\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data, \n",
    "        batch_size=batch_size_train,\n",
    "        shuffle=True)\n",
    "    \n",
    "    eval_loader = torch.utils.data.DataLoader(\n",
    "        eval_data, \n",
    "        batch_size=batch_size_eval,\n",
    "        shuffle=False)\n",
    "    \n",
    "    return train_loader, eval_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f236425b-15fb-4790-99fc-47c46cf7afc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader, eval_loader = GetDataLoaders(train_data, eval_data, batch_size_train=BATCH_SIZE, batch_size_eval=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8772749a-3797-4f19-9ca3-46a52c8f32a6",
   "metadata": {},
   "source": [
    "##### <b>Question:</b> Based on our batch size, what type of gradient descent will we be performing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0cf70a9-f58d-4bad-9263-d56a062c182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Emma test\n",
    "print(len(eval_data))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50cc0b02-ec25-4550-986a-51b61b220a4f",
   "metadata": {},
   "source": [
    "We will be performing mini-batch gradient descent because the batch size is greater than 1 but less than the dataset size (which is 10,000)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b170fb0-87f8-47e0-9a95-3cefc47f12b6",
   "metadata": {},
   "source": [
    "##### <b>Question:</b> Why do we need to shuffle our training data?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4077bae0-2353-47ff-a653-52eacb62871a",
   "metadata": {},
   "source": [
    "The training data needs to be shuffled to avoid the model learning specific patterns based on the order of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aac2c4-ba59-4d32-b1cb-92214d7af71b",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <b>Question:</b> Why don't we need to shuffle our evaluation data?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59cea600-feb2-4b11-9635-13ec2a0965eb",
   "metadata": {},
   "source": [
    "The model is not directly using the evaluation data to learn---it only is used to evaluate model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19461808-5940-4540-9d98-f64eb159f606",
   "metadata": {},
   "source": [
    "### Working with \"Tensors\"\n",
    "In PyTorch, a [**tensor**](https://pytorch.org/docs/stable/tensors.html) is a data type that represents a multi-dimensional array, much like the NumPy N-dimensional array and Pandas Dataframe types that we have been using so far. \n",
    "\n",
    "PyTorch tensors have a couple of extra features that are of particular interest to us in this Deep Learning project:\n",
    "\n",
    "1) Tensors provide support for [**automatic differentiation**](https://en.wikipedia.org/wiki/Automatic_differentiation), which calculates the derivatives we need for training our network.\n",
    "    * In previous notebooks, we implemented intuitive variants of the gradient descent algorithm to minimize our cost funtions.\n",
    "    * More commonly, derivatives are used to determine the direction and step size used to modify weights and biases.\n",
    "2) Tensors provide support for running on [CPUs](https://en.wikipedia.org/wiki/Central_processing_unit) or [GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit) (if available).\n",
    "    * Unfortunately, our current environment does not have access to GPU resources that we can leverage to speed up the training and evaluation process of our networks.\n",
    "    * I encourage you to make use of this feature if you have a computer with a GPU available to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e35098c-49de-47ee-b7b5-3741db37e64b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data type: <class 'torch.Tensor'>\n",
      "Training data shape: torch.Size([32, 1, 28, 28])\n",
      "Training data device: cpu\n",
      "Using CPU.\n"
     ]
    }
   ],
   "source": [
    "# Get a batch of images from the training dataset\n",
    "batch_iter = iter(train_loader)\n",
    "batch_images, batch_labels = next(batch_iter)\n",
    "\n",
    "# Print out a few statistics about our data\n",
    "print(\"Training data type: {}\".format(type(batch_images)))\n",
    "print(\"Training data shape: {}\".format(batch_images.shape))\n",
    "print(\"Training data device: {}\".format(batch_images.device))\n",
    "\n",
    "'''\n",
    "TO DO: As needed, play around with the tensor objects to get to know them\n",
    "'''\n",
    "# START your code here\n",
    "\n",
    "# STOP your code here\n",
    "\n",
    "# Check which devices are available, and cache the best one\n",
    "DEVICE = None\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"Using GPU.\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb0ccd8-df7f-440b-bc3f-150d357b459f",
   "metadata": {},
   "source": [
    "### Displaying input data with Matplotlib\n",
    "\n",
    "In the cell below, there is a utility function to display a configurable number of MNIST sample images.\n",
    "\n",
    "<u>Example usage</u>:\n",
    "```python\n",
    "DisplayImagesMNIST(image_data)\n",
    "```\n",
    "\n",
    "There is also a utility function to summarize some information about your input dataset as well as display some sample images.\n",
    "\n",
    "<u>Example usage</u>:\n",
    "```python\n",
    "SummarizeDatasetMNIST(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d426eba0-0f1d-41d9-b3a5-f306dc301f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to render a subset of images\n",
    "def DisplayImagesMNIST(image_data, num_to_show=5):\n",
    "    for idx in range(num_to_show):\n",
    "        \n",
    "        # Create a 1x5 plot of images (index from 1)\n",
    "        ax = plt.subplot(1, 5, idx+1)\n",
    "    \n",
    "        # Reshape from (1,28,28) to (28,28)\n",
    "        plt.imshow(image_data[idx].reshape(28, 28), cmap=\"gray_r\")\n",
    "        plt.xticks([]) # Don't show x-axis ticks\n",
    "        plt.yticks([]) # Don't show x-axis ticks\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "# Display some statistics about the dataset as well as a subset of images\n",
    "def SummarizeDatasetMNIST(data_loader, num_to_show=5):\n",
    "    # Get a batch of images from the training dataset\n",
    "    batch_iter = iter(data_loader)\n",
    "    batch_images, batch_labels = next(batch_iter)\n",
    "\n",
    "    # Print out a few statistics about our data\n",
    "    print(\"Image data type: {}\".format(type(batch_images)))\n",
    "    print(\"Image shape: {}\".format(batch_images.shape))\n",
    "    print(\"Image processing device: {}\".format(batch_images.device))\n",
    "    print(\"Number of images: {}\".format(len(data_loader.dataset)))\n",
    "    print(\"Number of batches: {}\".format(len(data_loader)))\n",
    "\n",
    "    # Render a subset of the images, along with their known labels\n",
    "    num_to_show = num_to_show if num_to_show < batch_images.shape[0] else batch_images.shape[0]\n",
    "    print(batch_labels[:num_to_show])\n",
    "    DisplayImagesMNIST(batch_images, num_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b282a017-a0cd-4ed0-b16f-69ad27aff357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data type: <class 'torch.Tensor'>\n",
      "Image shape: torch.Size([32, 1, 28, 28])\n",
      "Image processing device: cpu\n",
      "Number of images: 60000\n",
      "Number of batches: 1875\n",
      "tensor([9, 9, 4, 7, 7])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data type: <class 'torch.Tensor'>\n",
      "Image shape: torch.Size([32, 1, 28, 28])\n",
      "Image processing device: cpu\n",
      "Number of images: 10000\n",
      "Number of batches: 313\n",
      "tensor([7, 2, 1, 0, 4])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAABpCAYAAABF9zs7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAADU9JREFUeJzt3XuIVGUYx/F3t0IzZ1elUDdWJQVXMVNSxC67oiWbqemmpUgtEZEbW2mQYZmalzA1Cy3yEllg4qXUVLyEt1Aybam8bSbmbWMrzUKX1Fbb6S+fnhnOcc6M55w5Z+b7gYXfrDNzXvZ11tf3Pe/75ESj0agBAABZLTfdDQAAAOnHgAAAADAgAAAADAgAAIBhQAAAAAwDAgAAYBgQAAAAY8yNTp7U0NBgamtrTSQSMTk5OV63KWtEo1FTV1dnCgoKTG5uamMz+sZ99Etw0TfBRL8EV1J9E3WgpqYmaozhy6OvmpoaJ91A39AvfNE3gf6iX4L75aRvHM0QRCIRY4wxNTU1Ji8vz8lL4MD58+dNYWGh/HxTQd+4j34JLvommOiX4EqmbxwNCK5O3+Tl5dFRHrie6TH6xjv0S3DRN8FEvwSXk77hpkIAAMCAAAAAMCAAAACGAQEAADAMCAAAgGFAAAAAjMNth4Cd2bNnS7548aLk/fv3S/7ss88sX1tRUSG5d+/ekp944gk3mwgAcIAZAgAAwIAAAACwZIAUPP7445JXrlyZ8Pl2J2TNnz9f8pYtWySXlJRIbtOmTSpNhEuOHDkiuWPHjpLnzp0r+fnnn/e1TZnq77//lvzyyy9L1p+THj16SNafvbZt23rcOmQDZggAAAADAgAAwJIBHEp2maCoqEhyaWmp5GPHjkleu3at5KNHj0pesmSJ5FdffTX5xsI133//vWRdS/32229PR3MyWm1treRFixZJvuGGGyRXVVVJXrduneTKykqPW5f5vvvuO8llZWWST5w44fq1vvzyS8mdOnWSXFhY6Pq1ksEMAQAAYEAAAABYMoANPTVpjDGrV6+2fF6XLl0k6yWAW2+9VXLTpk0l19fXS+7Vq5fkffv2ST579mwKLYYXfvjhB8m6H/WUKlJ35swZyeXl5WlsCTZv3iz5n3/+8fRa+nflRx99JHnZsmWeXjcRZggAAAADAgAAkIYlA32uvb6T1hhjCgoKJDdu3FjyqFGjJLdq1Upyhw4dvGgijDG//vprzONoNCpZLxPoabbWrVsnfF9d++DHH3+0fM7AgQMdtxPuO3DggOR58+ZJfvLJJ9PRnIyjD3Vas2aN5G+//Tap99m5c6dk/fm86667JBcXF6fQwuxx5coVyRs2bPDtuvqAqTlz5kjWh1MZY8wtt9ziW5uMYYYAAAAYBgQAAMAwIAAAACYN9xDooh1OT4DSxT3y8vIkd+7c2bV2WdGnRo0bNy7mz/QaUCYaNGhQzGN9kmAkEpHcokWLpN53+fLlkvUWRATHTz/9JFmvaerTKpG6MWPGSNanECZr1apVllkXBFuxYoXku+++O+VrZart27dL/vrrryW/8sornl73zz//lHzo0CHJFy5ciHke9xAAAADfMSAAAAD+Lxl8+OGHkvXpdMbELgFUV1dL1gVWduzYIfmbb76RrKfJTp06lbAdN910k2R9qp7ebqffP77oRKYvGcS7nnrrs2bNknzkyBHL5+hTC3WG/2bOnCm5Xbt2krPt77ybBgwYIFlvEfz333+Teh/9u0pPJ588eVLy8ePHJffs2VNyQ0NDUtfKVHpb7YgRIyTrbexeF1XTJxUGCTMEAACAAQEAAEjDkkG/fv0sc7zS0lLL7//111+S9VKCns50cuJXo0aNJHfs2FFyUVGRZH0naPv27RO+J/63fv16yRMnTpSsi4a0bNlS8owZMyQ3adLE49Yhnt7xoz8/+rPh9x3PYffVV19JPnz4sOScnBzJTnYZjB49WnL//v0l5+fnS962bZvk6dOnW77PBx98ILmioiLhdTOV/vnou/qXLFkiWRfycov+90T/3dB/H9KNGQIAAMCAAAAApGHJ4Ho1b95cct++fS2fc62lCCuff/65ZL0k0bVrV8n6blQkVlVVJdmutrg+6KakpMTzNsGensLUbrvtNp9bEl7xB63p3xl//PFHwtfrnVLDhg2TPGnSJMl2y2l6F9CCBQssr6sPV7t06VLM6ysrKyXrHViZQBfUMya2iJHeWaB3ZHhh2rRpkvUyQZ8+fSQ3a9bM0zYkwgwBAABgQAAAAEK4ZOCW06dPS37uueck60ND9N3xyZ7Zn42GDBkiefPmzZbPKS8vl6yn0JBe+/fvt/x+fA0P2Lt8+XLMYyfLBMXFxZJ1nQ99AJETeslAH6rz0ksvSdZ1KeL7dfDgwZIzbUfVypUrYx7rn4PXuy30MtLSpUsl33jj///0TpgwQXK6l2uYIQAAAAwIAABAFi8ZvP/++5L18oG+y1MfygJruvaDLh+qdxboO9X19JgXh3/Aud27d0tevHix5O7du0t+8MEHfW1TNtB3s+ufe7LLBHb09P+nn34qee/eva68fxicO3dOsq5JE08vF3th4cKFks+cOSNZ1+2x2y2XDswQAAAABgQAACDLlgx27dolWZ+dr33xxReSu3Tp4nmbwq6srEyy3V3Vo0aNkpxpdzCH2datWyXrA7l0HZHGjRv72qZMYlfaeM+ePZ5eV++U0iWPr1V2WR9+pM/0Dyu9ZPnLL7/E/NnIkSN9a8fPP/9s+f2g/tvCDAEAAGBAAAAAsmzJQJ9hXV9fL/mBBx6Q3Lt3b1/bFEZr166VrEtQa/p87ilTpnjdJKRg3759lt8fPny4zy3JDPPnz4957KS0sRfWrVsnWX8+r1V2+Y033vC+YT6KRCKSu3XrFvNnBw4ckKxLErt1+JzetRZ/KNJV9957ryvXchszBAAAgAEBAADIgiWDixcvSt60aZPkRo0aSdbTZek+Szqozp49K/nNN9+UrJdeND1NxwFEwfHbb79J3rlzp+SioiLJQ4cO9bVNmWL9+vW+Xk8fdFNdXS1Zfz7txB+ClGm/926++WbJusSxMbHlkB9++GHJuu6DEwcPHpSsdxOcPHlSsl6m0XJzg/l/8WC2CgAA+IoBAQAAyPwlg1mzZknWd9w+9NBDku+55x5f2xRGb7/9tmS7M9F1+WN2FgTTxx9/LPn333+XrD8PCIfp06dL1rVZ7LRr107yJ598EvNnbdq0ca1dQTN58uSYx/qAJr3MM2LEiKTeV9do0UsDTspeP/XUU0ldyy/MEAAAAAYEAAAgQ5cM9DTQ1KlTJefn50t+/fXXfW1T2M2ZMyfhc/S0JTsLgknfAa01b97c55YgFQMGDJB8+PDhpF6rS+7ef//9rrUp6Dp16hTzeMWKFZL1MrJd3QE7w4YNs/x+eXm5ZLu6EHoXRJAwQwAAABgQAACADFoy0AfnvPDCC5KvXLkiWU+3UbPAfboPkj3oRC/n6NdevnxZ8rlz5yxfq0v3GmPMO++8k/B6+iz3t956S3KTJk0SNzbE9Dn32sCBA31uSebRd68bY1/+eOPGjZbff+aZZyTX1tYmvIbdoTd2/D44KQy6d+9uma/HHXfckfA5up7CnXfe6cp13cAMAQAAYEAAAABCvmSgp+RKS0slHz9+XLI+x1rvOID7unbtmvJrH3vsMcmtW7eWrA/PWbZsWcrvfy0tW7aUPGHCBE+ukU66ZoH+ecJdFRUVMY/HjRtn+Tx9fr5diWS77+vfeU7KK48ePTrhc+AuvawTv4x0VZCWCTRmCAAAAAMCAAAQ8iUDfZBEVVWV5XP0gTrt27f3vE2ZSu/QWLNmjevvrw8LcULvRLhWKdHBgwdL7tGjh+Vz7rvvvqSuHTarV6+WrHfd6LuqS0pKfG1TJiorK4t5PHPmTMlOzrdPli5hrA/fWbRokWS9/AZ/6N0fye4ESTdmCAAAAAMCAADAgAAAAJgQ3kOgi7P079/f8jmzZ8+WzAls7li1apVkvTZaX1+f8LXV1dWSnWwdfPrppyW3bdvW8jmPPvqo5PjiJTDmwoULku1Oxhs+fLhkJ1vYcG3xf1eXL18uWd938+6777pyvddee01yZWWlK++J63fp0iXL7we1oJHGDAEAAGBAAAAAQrhksGDBAsl2td31FqqwbfsIA7sT2JxYunSpiy2BHb0ts1mzZpIfeeQRyS+++KKfTco6xcXFllkvdS5cuFCyLjw1aNAgyc8++6xkffJd586d3WssXLN48WLJ+rM3ceLENLQmOcwQAAAABgQAACAkSwa6OMt7772XxpYA4aCXDHbv3p3GliCeLsSmMzJDz549JY8dO1Zy375909GcpDBDAAAAGBAAAICQLBns2rVLcl1dneVzOnToILlp06aetwkAgHh6t0jYMEMAAAAYEAAAgJAsGdjp1q2b5K1bt0pu0aJFGloDAEB4MUMAAAAYEAAAgJAsGYwfP94yAwAAdzBDAAAAnM0QXK2wdf78eU8bk22u/jx1BbNk0Tfuo1+Ci74JJvoluJLpG0cDgquHARUWFl5Hs2Cnrq7O5Ofnp/xaY+gbL9AvwUXfBBP9ElxO+iYn6mDY0NDQYGpra00kEjE5OTmuNTDbRaNRU1dXZwoKCkxubmqrN/SN++iX4KJvgol+Ca5k+sbRgAAAAGQ2bioEAAAMCAAAAAMCAABgGBAAAADDgAAAABgGBAAAwDAgAAAAxpj/AMMQO6S/AEAaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SummarizeDatasetMNIST(train_loader)\n",
    "SummarizeDatasetMNIST(eval_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df8185-20ff-4eb9-b3ef-80b58e4c1f78",
   "metadata": {},
   "source": [
    "## Simple Classifier Model\n",
    "\n",
    "### Defining the model inputs and outputs\n",
    "* The inputs of this classifier model will be the MNIST image samples that we loaded.\n",
    "* The outputs of this classifier will be predictions for each possible label.\n",
    "    * Note: This is a multi-class problem. Consider how many possible labels there are.\n",
    "\n",
    "### Defining the model structure\n",
    "In the call below, we will define our **neural network** model as a class called \"ClassifierNet\".\n",
    "\n",
    "Using the PyTorch framework, neural network models are **subclasses** of the [**Module**](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class.\n",
    "\n",
    "> PyTorch uses modules to represent neural networks. Modules are:\n",
    ">\n",
    "> * Building blocks of stateful computation. PyTorch provides a robust library of modules and makes it simple to define new custom modules, allowing for easy construction of elaborate, multi-layer neural networks.\n",
    "> * Tightly integrated with PyTorch’s autograd system. Modules make it simple to specify learnable parameters for PyTorch’s Optimizers to update.\n",
    "> * Easy to work with and transform. Modules are straightforward to save and restore, transfer between CPU / GPU / TPU devices, prune, quantize, and more.\n",
    ">\n",
    "> From the [PyTorch v 2.1 Documentation](https://pytorch.org/docs/stable/notes/modules.html)\n",
    "\n",
    "Implement the model below woth the following architecture:\n",
    "\n",
    "1) A linear (see: [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)) **hidden layer** with 4 neurons that uses the ReLU (see: [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html)) activation function (values between 0 and infinity).\n",
    "3) Another linear **hidden layer** with 8 neurons that uses the ReLU activation function (values between 0 and infinity).\n",
    "4) A linear **output layer** with \"OUTPUT_SIZE\" neurons that uses the Tanh (see: [F.tahn](https://pytorch.org/docs/stable/generated/torch.nn.functional.tanh.html#torch.nn.functional.tanh)) activation function (continuous values between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6eabc18-c93d-478d-8ba3-51ba5302fb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "'''\n",
    "TO DO: Define the size of the input to the neural network and the size of the output from the neural network.\n",
    "Hint: Review your lecture notes. What determines the size of the inputs and the size of the outputs?\n",
    "'''\n",
    "# START your code here\n",
    "INPUT_SIZE = 784        # MNIST 28 * 28 pixels\n",
    "OUTPUT_SIZE = 10        # 10 possible digit classes (0–9)\n",
    "# STOP your code here\n",
    "\n",
    "\n",
    "# Define the structure of the neural network\n",
    "class ClassifierNet(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.L1 = None # First hidden layer\n",
    "        self.L2 = None # Second hidden layer\n",
    "        self.LN = None # Output layer\n",
    "        \n",
    "        '''\n",
    "        TO DO: Instantiate the layers (L1-LN) according to the above description\n",
    "        '''\n",
    "        # START your code here\n",
    "        self.L1 = nn.Linear(INPUT_SIZE, 4)\n",
    "        self.L2 = nn.Linear(4, 8)\n",
    "        self.LN = nn.Linear(8, OUTPUT_SIZE)\n",
    "        # STOP your code here\n",
    "\n",
    "    # Defines the steps taken during the \"forward pass\"\n",
    "    def forward(self, input):\n",
    "        \n",
    "        # Get the input data into a shape we can work with (remove the \"channel\" axis of size \"1\")\n",
    "        data = input.view(input.size(0), INPUT_SIZE)\n",
    "\n",
    "        '''\n",
    "        TO DO: \n",
    "         - The input layer is  provided above\n",
    "         - Pass the data through the hidden and output layers, along with their respective activation functions as defined above\n",
    "        '''\n",
    "        # START your code here\n",
    "        data = F.relu(self.L1(data))\n",
    "        data = F.relu(self.L2(data))\n",
    "        data = F.tanh(self.LN(data))\n",
    "        # STOP your code here\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac997911-84aa-4ad5-8805-db2b274a5bfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training the model\n",
    "In our previous notebook (NB7) we trained our neuron by minimizing an error function using a version of the gradient descent algorithm.\n",
    "\n",
    "We do something similar below:\n",
    "\n",
    "1) For our **error function**, we use [cross entropy loss](https://en.wikipedia.org/wiki/Cross-entropy), which is well-suited to classification problems.\n",
    "   * Different error functions work better for different problems. For example, MSE is often used for regression problems. \n",
    "2) We let an [**optimizer**](https://pytorch.org/docs/stable/optim.html) calculate our derivitives for us (this indicates a direction and amount to move our weights and biases).\n",
    "   * There are different algorithms we could choose from, but here we stick with gradient descent [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD).\n",
    "   * Note: Although this optimizer class is named \"SGD\" for \"stochastic gradient descent\", it is possible to perform stochastic, mini-batch, or batch gradient descent, depending on your DataLoader.\n",
    "\n",
    "Training a model often takes a long time. For large networks it could take **hours** or **days**. For the default values of our model, training took under a minute for me. When you increase the number of neurons in each layer, add layers to the model, or change any hyperparameters, make sure to do so incrementally, and note the changes that it makes in terms of training time.\n",
    "\n",
    "<u>Implementation hints:</u>\n",
    "* Read the documentation for your optimizer. See: [torch.optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)\n",
    "    * Pay special attention to the \"zero_grad\" and \"step\" functions.\n",
    "* Read the documentation for your error function. See: [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
    "    * Pay special attention to the \"backward\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27e6c5ea-d4e6-46e1-89bc-cd66531e6756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a model using the provided training data\n",
    "def TrainModel(train_loader, classifier_net):\n",
    "    \n",
    "    # Hyperparameters used for training\n",
    "    EPOCHS = len(train_loader) * 2\n",
    "    LEARNING_RATE = 0.0001\n",
    "    MOMENTUM = 0.99\n",
    "    \n",
    "    '''\n",
    "    TO DO: \n",
    "     - Specify the algorithm to use for minimizing the error\n",
    "     - Specify the error function we will be minimizing\n",
    "    '''\n",
    "    # START your code here\n",
    "    optimizer = torch.optim.SGD(classifier_net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "    error_function = nn.CrossEntropyLoss()\n",
    "    # STOP your code here\n",
    "\n",
    "    # Each epoch we will iterate over a random batch of the training data\n",
    "    batch_iter = iter(train_loader)\n",
    "    \n",
    "    print(\"Started training...\")\n",
    "\n",
    "    # Train the model iteratively, over a configurable number of epochs\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        # If we run through all the batches, reset the iterator\n",
    "        if (epoch % len(train_loader)) == 0:\n",
    "            batch_iter = iter(train_loader)\n",
    "            \n",
    "        # Get the next \"random\" batch. ach batch consists of inputs (feature vectors) and the known labels for each data item.\n",
    "        inputs, labels = next(batch_iter)\n",
    "\n",
    "        '''\n",
    "        NOTE:\n",
    "         - Here is where we start letting the optimizer calculate our derivitives for us!\n",
    "        TO DO: \n",
    "         - Use your optimizer to zero-out the gradients for the weights and biases. Otherwise they would accumulate over each batch.\n",
    "         - Run the \"forward pass\" through your model\n",
    "             - Data goes from Input Layer -> Hidden Layer 1 -> ... -> Hidden Layer N -> Output Layer\n",
    "         - Compute the error using your error function (defined above)\n",
    "         - Using your error function result, run the \"backpropagation\" or \"backwards pass\" through the model\n",
    "            - Error goes from Output Layer -> Hidden Layer N -> ... -> Hidden Layer 1 -> Input Layer\n",
    "        - Using your optimizer, Update the weights and biases\n",
    "        '''\n",
    "        # START your code here\n",
    "        optimizer.zero_grad()                 # 1 - optimizer\n",
    "        outputs = classifier_net(inputs)      # 2 - forward pass\n",
    "        loss = error_function(outputs, labels) # 3 - error\n",
    "        loss.backward()                       # 4 - backpropagation\n",
    "        optimizer.step()                      # 5 - update weights and biases\n",
    "        # STOP your code here\n",
    "\n",
    "    print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c5b507f-451e-4c9a-92bd-7a7ec5bcd13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training...\n",
      "Finished Training.\n",
      "CPU times: total: 4min 27s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ^This will display how long it takes to execute this cell\n",
    "\n",
    "# Instantiate the neural network model to train\n",
    "classifier_net = ClassifierNet() \n",
    "\n",
    "# Train the model\n",
    "TrainModel(train_loader, classifier_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d90259-ce6e-4501-bed3-31796d637317",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0314dca6-62c2-40c5-89e0-c67d0b0ba674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate a single batch and visualize the prediced vs true labels\n",
    "def VisualizeSingleBatchEvaluation(eval_loader, model):\n",
    "    # Get a batch of data for evaluation/testing (not in the training data)\n",
    "    eval_iter = iter(eval_loader)\n",
    "    batch_images, batch_labels = next(eval_iter)\n",
    "\n",
    "    # Run a batch of evaluation data through the trained model\n",
    "    outputs = model(batch_images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Show some sample true vs predicted labels, as well as the corresponding images\n",
    "    NUM_IMAGES_TO_SHOW = 5\n",
    "    print(\"Truth:     {}\".format(str(batch_labels[:NUM_IMAGES_TO_SHOW])))\n",
    "    print(\"Predicted: {}\".format(str(predicted[:NUM_IMAGES_TO_SHOW])))\n",
    "    DisplayImagesMNIST(batch_images, NUM_IMAGES_TO_SHOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b55b2db-4a6f-4033-8400-6d74cacc35f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth:     tensor([7, 2, 1, 0, 4])\n",
      "Predicted: tensor([9, 2, 3, 6, 9])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VisualizeSingleBatchEvaluation(eval_loader, classifier_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee7d45ff-f8a4-4671-b30d-401cd3d2f3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the accuracy of a model using the provided evaluation data\n",
    "def CalculateAccuracy(eval_loader, model):\n",
    "    # Store the number of correct predictions and total predictions\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Since we're not training, we don't need to calculate the gradients\n",
    "    with torch.no_grad():\n",
    "        for data in eval_loader:\n",
    "            images, labels = data\n",
    "        \n",
    "            # Run the images through the network\n",
    "            outputs = model(images)\n",
    "        \n",
    "            # Predict the labels with the highest probability\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a6613b4-4aa4-44a6-9d56-7d2a329d454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy accross labels: 38.59\n",
      "CPU times: total: 17.9 s\n",
      "Wall time: 6.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ^This will display how long it takes to execute this cell\n",
    "\n",
    "accuracy = CalculateAccuracy(eval_loader, classifier_net)\n",
    "print('Accuracy accross labels: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8579fc5-5df8-4fc9-a9dc-ae056ba07915",
   "metadata": {},
   "source": [
    "## Creating a Better Model\n",
    "\n",
    "### Defining the new model\n",
    "Experiment with different neural network architectures to achieve better results.\n",
    "\n",
    "A few ideas of things to try include:\n",
    "* Stick with linear layers but try different:\n",
    "    * Numbers of hidden layers\n",
    "    * Number of nodes within the layers\n",
    "    * Activation functions\n",
    "* Try different types of layers, such as:\n",
    "    * Convolution layers, see: [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "    * Pooling layers, see: [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77a345ee-74d5-4177-8669-a2418084017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the structure of the neural netowrk\n",
    "class BetterClassifierNet(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        '''\n",
    "        TO DO: Instantiate any layers you need\n",
    "        '''\n",
    "        # START your code here\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)     # layer 1\n",
    "        self.pool = nn.MaxPool2d(2, 2)                       # pool layer\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)    # layer 2\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, 64)                 # connected layer\n",
    "        self.fc2 = nn.Linear(64, 10)                   # output layer\n",
    "        # STOP your code here\n",
    "\n",
    "    # Defines the steps taken during the \"forward pass\"\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        TO DO: \n",
    "         - Perform any reshaping operations you need to perform on the data\n",
    "         - Pass the data through each of your layers and their respective activation functions\n",
    "        '''\n",
    "        # START your code here\n",
    "        data = F.relu(self.conv1(input))     # conv1 + ReLU\n",
    "        data = self.pool(data)               # pooling\n",
    "        data = F.relu(self.conv2(data))      # conv2 + ReLU\n",
    "        data = self.pool(data)               # pooling again\n",
    "        data = data.view(-1, 16 * 7 * 7)     # 4D tensor ---> 2D (batch_size, features)\n",
    "        data = F.relu(self.fc1(data))        # fully connected + ReLU\n",
    "        data = F.tanh(self.fc2(data))        # output layer + tanh\n",
    "        # STOP your code here\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873936c1-5fe9-4bd8-bb12-bbc6c61c4422",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "Re-use the same training function you defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "265e5ecd-e4d2-4300-b10c-8bf692056fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training...\n",
      "Finished Training.\n",
      "CPU times: total: 5min 36s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ^This will display how long it takes to execute this cell\n",
    "\n",
    "# Instantiate the neural network model to train\n",
    "better_classifier_net = BetterClassifierNet() \n",
    "\n",
    "# Train the model\n",
    "TrainModel(train_loader, better_classifier_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dbb75c-2aa3-4b6a-a652-a0c585a025be",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "Evaluate the model by re-using the evaluation functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30b97dee-54fc-4176-b47b-42ee1c4fe630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth:     tensor([7, 2, 1, 0, 4])\n",
      "Predicted: tensor([7, 2, 1, 0, 4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VisualizeSingleBatchEvaluation(eval_loader, better_classifier_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17806086-98bb-4389-9683-10af1a52770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy accross labels: 92.94\n",
      "CPU times: total: 15.9 s\n",
      "Wall time: 5.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ^This will display how long it takes to execute this cell\n",
    "\n",
    "accuracy = CalculateAccuracy(eval_loader, better_classifier_net)\n",
    "print('Accuracy accross labels: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922fe0f-bc04-4a07-b221-2b642237ac71",
   "metadata": {},
   "source": [
    "### Checkpoint for accuracy\n",
    "Use the checkpoint below to determine if your \"Better\" classification model is performing well enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f28c3d8c-54ba-4af0-a0bf-98df43d04970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed checkpoint.\n"
     ]
    }
   ],
   "source": [
    "# Adding a checkpoint for improving the model's accuracy\n",
    "TARGET_ACCURACY = 90\n",
    "assert accuracy > TARGET_ACCURACY, \"Try to improve the model's accuracy. Current accuracy: {}\".format(accuracy)\n",
    "print(\"Passed checkpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610eb1f-7a4e-4dbb-9420-32109bf44ea8",
   "metadata": {},
   "source": [
    "Congratulations, you have reached the end of this notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
